import os
import tempfile
import uuid
import asyncio
from typing import List, Dict, Union

import streamlit as st
from dotenv import load_dotenv
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.document_loaders import PyPDFLoader
from langchain_google_genai import GoogleGenerativeAIEmbeddings
from langchain_community.vectorstores import FAISS
import google.generativeai as genai
from gtts import gTTS

# Load environment variables
load_dotenv()

def init_session_state() -> None:
    """Initialize Streamlit session state with default values."""
    defaults = {
        "setup_complete": False,
        "vector_store": None,
        "processed_documents": [],
        "messages": [],
        "current_api_key": ""
    }
    
    for key, value in defaults.items():
        if key not in st.session_state:
            st.session_state[key] = value

def get_api_key() -> str:
    """
    Get API key from secrets (Instant Demo) or user input.
    Returns the valid key or empty string.
    """
    # 1. Check Streamlit Secrets (Best for deployment)
    if "GOOGLE_API_KEY" in st.secrets:
        st.session_state.current_api_key = st.secrets["GOOGLE_API_KEY"]
        return st.secrets["GOOGLE_API_KEY"]
    
    # 2. Check Environment Variables (Best for local .env)
    env_key = os.getenv("GOOGLE_API_KEY")
    if env_key:
        st.session_state.current_api_key = env_key
        return env_key

    # 3. Fallback to User Input
    return st.session_state.get("user_provided_key", "")

def setup_sidebar() -> None:
    """Configure sidebar with API settings."""
    with st.sidebar:
        st.header("âš™ï¸ Configuration")
        st.markdown("---")
        
        # Check if we have a secret key
        secret_key = "GOOGLE_API_KEY" in st.secrets or os.getenv("GOOGLE_API_KEY")
        
        if secret_key:
            st.success("âœ… API Key loaded from system")
            st.caption("Using host provided credentials")
        else:
            st.text_input(
                "Google API Key",
                type="password",
                help="Enter your Google Gemini API Key",
                key="user_provided_key"
            )
            if st.session_state.user_provided_key:
                st.session_state.current_api_key = st.session_state.user_provided_key
        
        st.markdown("---")
        # Document list will be rendered in main after uploader

def process_pdf_data(file_data: bytes, file_name: str) -> List:
    """Helper to process PDF bytes directly."""
    try:
        with tempfile.NamedTemporaryFile(delete=False, suffix='.pdf') as tmp_file:
            tmp_file.write(file_data)
            tmp_file_path = tmp_file.name
            
        loader = PyPDFLoader(tmp_file_path)
        documents = loader.load()
        
        # Add source metadata
        for doc in documents:
            doc.metadata.update({
                "source_type": "pdf",
                "file_name": file_name
            })
        
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=400
        )
        
        # Cleanup temp file
        os.unlink(tmp_file_path)
        
        return text_splitter.split_documents(documents)
    except Exception as e:
        st.error(f"ğŸ“„ PDF processing error: {str(e)}")
        return []

def update_vector_store(documents: List, api_key: str) -> None:
    """Update or create FAISS vector store."""
    if not api_key:
        raise ValueError("Google API Key not provided")

    embeddings = GoogleGenerativeAIEmbeddings(
        model="models/embedding-001",
        google_api_key=api_key
    )
    
    if st.session_state.vector_store is None:
        st.session_state.vector_store = FAISS.from_documents(documents, embeddings)
    else:
        st.session_state.vector_store.add_documents(documents)

def generate_gemini_response(context: str, query: str, api_key: str) -> str:
    """Generate response using Google Gemini."""
    genai.configure(api_key=api_key)
    model = genai.GenerativeModel('gemini-2.5-flash')
    
    prompt = f"""You are a helpful assistant. Use the following context to answer the user's question.    
Context:
{context}

User Question: {query}

Please provide a clear, concise answer that can be easily spoken out loud. Avoid using markdown formatting like bold or italics in the response text as it will be read by text-to-speech."""

    response = model.generate_content(prompt)
    return response.text

def generate_audio(text: str) -> str:
    """Generate MP3 using gTTS."""
    tts = gTTS(text=text, lang='en', slow=False)
    temp_dir = tempfile.gettempdir()
    audio_path = os.path.join(temp_dir, f"response_{uuid.uuid4()}.mp3")
    tts.save(audio_path)
    return audio_path

async def process_query(query: str, api_key: str) -> Dict:
    """Process user query and generate voice response."""
    try:
        if not st.session_state.vector_store:
            raise Exception("Vector store not initialized")

        # Search documents
        search_results = st.session_state.vector_store.similarity_search(query, k=10)
        
        if not search_results:
            raise Exception("No relevant documents found")
            
        # Prepare context
        context = ""
        sources = []
        for i, doc in enumerate(search_results, 1):
            source = doc.metadata.get('file_name', 'Unknown Source')
            context += f"From {source}:\n{doc.page_content}\n\n"
            sources.append(source)
            
        # Generate text response
        text_response = generate_gemini_response(
            context, 
            query, 
            api_key
        )
        
        # Generate audio
        audio_path = generate_audio(text_response)
        
        return {
            "status": "success",
            "text_response": text_response,
            "audio_path": audio_path,
            "sources": list(set(sources))
        }
    
    except Exception as e:
        return {
            "status": "error",
            "error": str(e)
        }

def load_default_resume(api_key: str):
    """Loads resume.pdf if it exists and nothing else is loaded."""
    if os.path.exists("resume.pdf") and "resume.pdf" not in st.session_state.processed_documents:
        with st.status("ğŸš€ Launching Demo Mode...", expanded=True) as status:
            st.write("ğŸ“„ Loading default resume...")
            try:
                with open("resume.pdf", "rb") as f:
                    file_data = f.read()
                
                documents = process_pdf_data(file_data, "resume.pdf")
                if documents:
                    st.write("ğŸ§  Indexing knowledge base...")
                    update_vector_store(documents, api_key)
                    st.session_state.processed_documents.append("resume.pdf")
                    st.session_state.setup_complete = True
                    status.update(label="âœ… Demo Ready! Ask away.", state="complete", expanded=False)
                    st.rerun()
            except Exception as e:
                status.update(label="âŒ Demo Load Failed", state="error")
                st.error(f"Could not load default resume: {str(e)}")

def process_uploaded_files(files: List, api_key: str):
    """Process a list of uploaded files."""
    if not api_key:
        st.warning("âš ï¸ Please provide your Google API Key first!")
        return

    for file in files:
        if file.name not in st.session_state.processed_documents:
            with st.status(f"Processing {file.name}...", expanded=True) as status:
                try:
                    st.write("ğŸ“„ Parsing PDF content...")
                    file_bytes = file.getvalue()
                    documents = process_pdf_data(file_bytes, file.name)
                    
                    if documents:
                        st.write("ğŸ§  Generating embeddings & indexing...")
                        update_vector_store(documents, api_key)
                        st.session_state.processed_documents.append(file.name)
                        st.session_state.setup_complete = True
                        status.update(label=f"âœ… {file.name} added!", state="complete", expanded=False)
                except Exception as e:
                    status.update(label="âŒ Error processing", state="error")
                    st.error(f"Error processing {file.name}: {str(e)}")
    
    # Rerun if we processed anything to update state
    if files:
        st.rerun()

def main() -> None:
    """Main application function."""
    st.set_page_config(
        page_title="Voice RAG Agent",
        page_icon="ğŸ™ï¸",
        layout="wide",
        initial_sidebar_state="expanded"
    )

    # Custom CSS
    st.markdown("""
        <style>
        .stChatInput { padding-bottom: 20px; }
        .stSpinner { text-align: center; }
        </style>
    """, unsafe_allow_html=True)
    
    init_session_state()
    setup_sidebar()
    
    # Get the active API key
    active_key = get_api_key()

    # Sidebar Upload Section
    with st.sidebar:
        st.header("ğŸ“„ Add Documents")
        sidebar_uploads = st.file_uploader(
            "Upload PDFs", 
            type=["pdf"],
            accept_multiple_files=True,
            key="sidebar_uploader"
        )
        if sidebar_uploads:
            process_uploaded_files(sidebar_uploads, active_key)
            
        if st.session_state.processed_documents:
            st.markdown("---")
            st.header("ğŸ“š Knowledge Base")
            for doc in st.session_state.processed_documents:
                st.caption(f"ğŸ“„ {doc}")
            
        st.markdown("### About")
        st.info(
            "This agent uses **Gemini 2.5 Flash** for reasoning and **FAISS** for retrieval. "
            "Upload a PDF, ask a question, and get a voice response!"
        )

    st.title("ğŸ™ï¸ Voice RAG Agent")
    st.caption("Powered by **Gemini 2.5 Flash** & **FAISS**")
    
    # Automatic Demo Loader
    if active_key and not st.session_state.setup_complete:
        if os.path.exists("resume.pdf"):
            load_default_resume(active_key)
    
    # Main Interface
    if not st.session_state.setup_complete:
        st.markdown("""
        <div style='text-align: center; padding: 2rem; border: 2px dashed #cccccc; border-radius: 10px; margin-bottom: 2rem;'>
            <h3>ğŸ‘‹ Welcome!</h3>
            <p>Upload a PDF document to start chatting.</p>
        </div>
        """, unsafe_allow_html=True)
        
        col1, col2, col3 = st.columns([1, 2, 1])
        with col2:
            # Center uploader for empty state
            center_upload = st.file_uploader(
                "Upload PDF Document", 
                type=["pdf"], 
                key="center_uploader"
            )
            
            if center_upload:
                process_uploaded_files([center_upload], active_key)

    else:
        # Chat Interface
        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])
                if "audio_path" in message:
                    st.audio(message["audio_path"], format="audio/mp3")
                    with open(message["audio_path"], "rb") as f:
                         st.download_button("â¬‡ï¸ Download Audio", f, file_name="response.mp3", mime="audio/mp3", key=f"dl_{uuid.uuid4()}")
                if "sources" in message:
                    with st.expander("ğŸ“š Sources"):
                        for source in message["sources"]:
                            st.write(f"- {source}")

        if prompt := st.chat_input("Ask a question about your documents..."):
            if not st.session_state.setup_complete:
                 st.error("Please upload a document first.")
            else:
                # Add user message
                st.session_state.messages.append({"role": "user", "content": prompt})
                with st.chat_message("user"):
                    st.markdown(prompt)

                # Generate response
                with st.chat_message("assistant"):
                    with st.spinner("Thinking..."):
                        result = asyncio.run(process_query(prompt, active_key))
                    
                    if result["status"] == "success":
                        st.markdown(result["text_response"])
                        
                        # Audio and controls
                        col_audio, col_dl = st.columns([3, 1])
                        with col_audio:
                            st.audio(result["audio_path"], format="audio/mp3")
                        with col_dl:
                            with open(result["audio_path"], "rb") as f:
                                st.download_button(
                                    label="â¬‡ï¸ Download",
                                    data=f,
                                    file_name="response.mp3",
                                    mime="audio/mp3",
                                    key=f"dl_new_{uuid.uuid4()}"
                                )
                        
                        # Sources
                        with st.expander("View Sources"):
                            for source in result["sources"]:
                                st.write(f"- {source}")
                        
                        # Save to history
                        st.session_state.messages.append({
                            "role": "assistant",
                            "content": result["text_response"],
                            "audio_path": result["audio_path"],
                            "sources": result["sources"]
                        })
                    else:
                        st.error(f"Error: {result.get('error')}")

if __name__ == "__main__":
    main()
